{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import svm\n",
    "import numpy as np\n",
    "import shap\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from scipy import stats\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "import lightgbm as lgb\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "import lightgbm as lgb\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "sys.path.append('../../')\n",
    "from util import Transform, PredictWay, get_k_fold_data, dnn\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import auc\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['font.sans-serif']=['Microsoft YaHei']\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.model_selection import permutation_test_score\n",
    "from metric import getMATRIX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "preturn\n",
    "'''\n",
    "\n",
    "MATRIX = []\n",
    "def str2Nan(x):\n",
    "    try:\n",
    "        return float(x)\n",
    "    except:\n",
    "        return np.nan\n",
    "seed=4 \n",
    "patient = pd.read_excel('../../)\n",
    "# put into the data\n",
    "\n",
    "\n",
    "transform = Transform(seed_num=seed)\n",
    "patient = transform.confuse(patient) \n",
    "# X, Y = transform.drop(patient,startXIndex=0,YIndex=2,dropColunm=['肿瘤1，结核4，慢性炎症2，急性炎症3，漏出液0'])    \n",
    "# X, Y = transform.drop(patient,startXIndex=0,YIndex=3,dropColunm=['恶性1，良性0'])    \n",
    "X, Y = transform.drop(patient,startXIndex=0,YIndex=-1,dropColunm=['Y'])    \n",
    "\n",
    "for name in X.columns:\n",
    "    X[name] = X[name].apply(str2Nan)\n",
    "    X[name] = X[name].fillna(X[name].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "kfold\n",
    "'''\n",
    "k = 10\n",
    "X = transform.normalization(X)\n",
    "result_svm, result_gbdt,result_tree,result_randomtree,result_lg,result_knn,result_lgb = [],[], [], [],[],[],[]\n",
    "false_index = []\n",
    "test_x, test_y = X[-200:],Y[-200:]\n",
    "X, Y = X[:-200],Y[:-200]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ModelDict = {\n",
    "    'SVM':svm.SVC(random_state=seed, probability=True),\n",
    "    'DT':DecisionTreeClassifier(max_depth=10,\n",
    "                                          random_state=seed),\n",
    "    'GBDT':GradientBoostingClassifier(random_state=seed),\n",
    "    'RF':RandomForestClassifier(random_state=seed,\n",
    "                                          min_samples_leaf=10),\n",
    "    'KNN':KNeighborsClassifier(),\n",
    "    'LR':LogisticRegression(random_state=400,max_iter=100),\n",
    "    'XGB':XGBClassifier(),\n",
    "    'ET':ExtraTreesClassifier(n_estimators=5, random_state=42),\n",
    "    'Ada':AdaBoostClassifier(n_estimators=50, random_state=42),\n",
    "    'LightGBM':lgb.LGBMClassifier(num_leaves=400,random_state=42,verbosity=-1),\n",
    "    'DNN':dnn}  \n",
    "for i in range(k):\n",
    "    if i!=4:\n",
    "        continue\n",
    "    print('第{:d}代'.format(i+1))\n",
    "    X_train, y_train, x_valid, y_valid,Y_index = get_k_fold_data(k,i,X,Y,transform.confuse_index)\n",
    "    pre = PredictWay(X_train, y_train, x_valid, y_valid,seed,Y_index)\n",
    "    for model_name, model in ModelDict.items():\n",
    "        matric = pre.model_train(model_name, model)\n",
    "        if model_name=='LightGBM':\n",
    "            model_shap = pre.model_fit\n",
    "    pre.show_roc()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = {\n",
    "    'LightGBM':[]\n",
    "}\n",
    "\n",
    "'''\n",
    "获取特征重要性\n",
    "'''\n",
    "temp = model_shap.feature_importances_[:]\n",
    "print(temp)\n",
    "importance = []\n",
    "for i in range(len(temp)):\n",
    "    importance.append(temp.argmax())\n",
    "    temp[temp.argmax()]=-1\n",
    "importance.reverse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[X.columns[importance[-10:]]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "绘制kfold的roc\n",
    "'''\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "roc_lgbs = []\n",
    "X_in = X.drop(X.columns[importance[:12]],axis=1)  \n",
    "X_test_drop = test_x.drop(X.columns[importance[:12]],axis=1)\n",
    "k = 5\n",
    "false_index = []\n",
    "for i in range(k):\n",
    "    print('第{:d}代'.format(i+1))\n",
    "    X_train, y_train, x_valid, y_valid,Y_index = get_k_fold_data(k,i,X_in,Y,transform.confuse_index)\n",
    "    pre = PredictWay(X_train, y_train, x_valid, y_valid,seed,Y_index)\n",
    "    pre.show = False\n",
    "    pre.model_train('LightGBM',ModelDict['LightGBM'])\n",
    "    f,t = pre.dict_auc['LightGBM']\n",
    "    roc_lgbs.append([f,t])\n",
    "    result = np.array(pre.model_fit.predict_proba(X_test_drop))[:, 1]\n",
    "    f, t, th = roc_curve(test_y, result)\n",
    "    print('外部验证集 最终模型auc：', auc(f,t)) \n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "tprs = []\n",
    "mean_fpr = np.linspace(0,1,100)\n",
    "for index, i in enumerate(roc_lgbs):\n",
    "    plt.plot(i[0],i[1], alpha = 0.3, label=f'ROC fold {index}(AUC={auc(i[0],i[1]):.4f})')\n",
    "    # sum0 += i[0]\n",
    "    # sum1 += i[1]\n",
    "    tprs.append(np.interp(mean_fpr, i[0], i[1]))\n",
    "    tprs[-1][0] = 0.0\n",
    "mean_tpr = np.mean(tprs, axis=0)\n",
    "mean_tpr[-1] = 1.0\n",
    "mean_auc = auc(mean_fpr, mean_tpr)\n",
    "plt.plot(mean_fpr,mean_tpr,color='b',label=r'Mean ROC (area=%0.4f)'%mean_auc,lw=2,alpha=.8)\n",
    "std_tpr = np.std(tprs, axis=0)\n",
    "tprs_upper=np.minimum(mean_tpr+std_tpr,1)\n",
    "tprs_lower=np.maximum(mean_tpr-std_tpr,0)\n",
    "print(mean_fpr, tprs_lower, tprs_upper)\n",
    "plt.fill_between(mean_fpr,tprs_lower,tprs_upper,color='gray',alpha=.2,label='± 1 SD')\n",
    "plt.plot([0,1],[0,1],linestyle='--',lw=2,color='r',label='Chance')\n",
    "plt.xlabel('False Positive Rate(1-specificity)')\n",
    "plt.ylabel('True Positive Rate(Sensitivity)')\n",
    "plt.title('Five-fold')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "外部验证 10features\n",
    "'''\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "f, t, th = roc_curve(test_y, result)\n",
    "print('auc:', auc(f,t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print([importance])\n",
    "result = {}\n",
    "for index_i in range(len(importance)):\n",
    "    X_drop = X.drop(X.columns[importance[:index_i]],axis=1)  \n",
    "    k = 5\n",
    "    for i in range(k):\n",
    "        if i!=4:\n",
    "            continue\n",
    "        X_train, y_train, x_valid, y_valid,Y_index = get_k_fold_data(k,i,X_drop,Y,transform.confuse_index)\n",
    "        pre = PredictWay(X_train, y_train, x_valid, y_valid,seed,Y_index)\n",
    "        for model_name, model in ModelDict.items():\n",
    "            matric = pre.model_train(model_name, model)\n",
    "    for model_name, list_f_t in pre.dict_auc.items():\n",
    "        result.setdefault(model_name,[]).append(auc(list_f_t[0], list_f_t[1]))\n",
    "    print(result)\n",
    "\n",
    "\n",
    "result['GBDT'].reverse()\n",
    "result['LightGBM'].reverse()\n",
    "result['SVM'].reverse()\n",
    "result['DT'].reverse()\n",
    "result['RF'].reverse()\n",
    "# result['LR'].reverse()\n",
    "result['KNN'].reverse()\n",
    "result['ET'].reverse()\n",
    "result['XGB'].reverse()\n",
    "result['DNN'].reverse()\n",
    "result['Ada'].reverse()\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.xticks(range(2, 19, 1), labels=[str(i) for i in range(2, 19, 1)])\n",
    "indice = np.arange(3, 19, 1)\n",
    "plt.xlabel('Numbers of features')\n",
    "plt.ylabel('Area under the ROC')\n",
    "plt.plot(indice,result['GBDT'][2:19:1],':',label='GBDT')\n",
    "plt.plot(indice,result['LightGBM'][2:19:1],'--',label='LightGBM')\n",
    "plt.plot(indice,result['SVM'][2:19:1],'-.',label='SVM')\n",
    "plt.plot(indice,result['DT'][2:19:1],'-',label='DT')\n",
    "plt.plot(indice,result['RF'][2:19:1],'-.',label='RF')\n",
    "plt.plot(indice,result['ET'][2:19:1],'-.',label='ET')\n",
    "plt.plot(indice,result['Ada'][2:19:1],':',label='AdaBoost')\n",
    "plt.plot(indice,result['DNN'][2:19:1],':',label='DNN')\n",
    "plt.plot(indice,result['XGB'][2:19:1],':',label='XGB')\n",
    "plt.plot(indice,result['KNN'][2:19:1],'--',label='KNN')\n",
    "plt.scatter(indice,result['GBDT'][2:19:1],s=20)\n",
    "plt.scatter(indice,result['LightGBM'][2:19:1],s=20)\n",
    "plt.scatter(indice,result['SVM'][2:19:1],s=20)\n",
    "plt.scatter(indice,result['DT'][2:19:1],s=20)\n",
    "plt.scatter(indice,result['RF'][2:19:1],s=20)\n",
    "plt.scatter(indice,result['ET'][2:19:1],s=20)\n",
    "plt.scatter(indice,result['XGB'][2:19:1],s=20)\n",
    "plt.scatter(indice,result['Ada'][2:19:1],s=20)\n",
    "plt.scatter(indice,result['DNN'][2:19:1],s=20)\n",
    "plt.scatter(indice,result['KNN'][2:19:1],s=20)\n",
    "\n",
    "plt.axvline(11,c='black',ls='-.')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_metric = {\n",
    "    'AUC':[],\n",
    "    'Sensitivity':[],\n",
    "    'Specificity':[],\n",
    "    'F1':[],\n",
    "    'PPV':[],\n",
    "    'NPV':[],\n",
    "    'Acc':[]\n",
    "}\n",
    "from scipy.stats import ttest_ind\n",
    "result_imp = []\n",
    "for index_i in range(len(importance)):\n",
    "    X_in = X.drop(X.columns[importance[:index_i]],axis=1)  \n",
    "    Xtest_in = test_x.drop(test_x.columns[importance[:index_i]],axis=1)  \n",
    "    k = 5\n",
    "    result_svm, result_gbdt,result_tree,result_randomtree,result_lg,result_knn,result_lgb = [],[], [], [],[],[],[]\n",
    "    false_index = []\n",
    "    for i in range(k):\n",
    "        if i!=4:\n",
    "            continue\n",
    "        X_train, y_train, x_valid, y_valid,Y_index = get_k_fold_data(k,i,X_in,Y,transform.confuse_index)\n",
    "        pre = PredictWay(X_train, y_train, x_valid, y_valid,seed,Y_index)\n",
    "        sensitive,specificity,ppv,npv,acc,f1 = pre.model_train('LightGBM',lgb.LGBMClassifier(num_leaves=400,random_state=42,verbosity=-1))\n",
    "        #  'LightGBM':lgb.LGBMClassifier(num_leaves=400,random_state=42,verbosity=-1)\n",
    "        f,t = pre.dict_auc['LightGBM'][0], pre.dict_auc['LightGBM'][1]\n",
    "        if X_train.shape[1]==18:\n",
    "            result_imp.append([f,t,22,auc(f,t),None,None])\n",
    "            auc0 = auc(f,t)\n",
    "            result0 = pre.result\n",
    "        if X_train.shape[1] in [11,10,9,3]:\n",
    "            result_imp.append([f,t,X_train.shape[1],auc(f,t),auc0-auc(f,t),ttest_ind(auc(f,t), auc0)])\n",
    "        # if X_train.shape[1]==10:\n",
    "        #     result_imp.append([f,t,10,auc(f,t),0.0029,0.4131])\n",
    "        # if X_train.shape[1]==9:\n",
    "        #     result_imp.append([f,t,9,auc(f,t),0.0145,0.2090])\n",
    "        # if X_train.shape[1]==3:\n",
    "        #     result_imp.append([f,t,3,auc(f,t),0.1184,0.00015])\n",
    "    result_metric['AUC'].append(auc(f,t))\n",
    "    result_metric['Sensitivity'].append(sensitive)\n",
    "    result_metric['Specificity'].append(specificity)\n",
    "    result_metric['F1'].append(f1)\n",
    "    result_metric['PPV'].append(ppv)\n",
    "    result_metric['NPV'].append(npv)\n",
    "    result_metric['Acc'].append(acc)\n",
    "'''\n",
    "画图\n",
    "'''\n",
    "result_metric['AUC'].reverse()\n",
    "result_metric['Sensitivity'].reverse()\n",
    "result_metric['Specificity'].reverse()\n",
    "result_metric['F1'].reverse()\n",
    "result_metric['NPV'].reverse()\n",
    "result_metric['PPV'].reverse()\n",
    "result_metric['Acc'].reverse()\n",
    "plt.figure(figsize=(10,8))\n",
    "plt.xticks(range(1,19,1), labels=[str(i) for i in range(1,19,1)])\n",
    "\n",
    "print(result_metric['AUC'])\n",
    "print(result_metric['Sensitivity'])\n",
    "print(result_metric['Specificity'])\n",
    "print(result_metric['F1'])\n",
    "print(result_metric['NPV'])\n",
    "print(result_metric['PPV'])\n",
    "print(result_metric['Acc'])\n",
    "\n",
    "\n",
    "indice = np.arange(3,19,1)\n",
    "plt.xlabel('Numbers of features')\n",
    "plt.ylabel('Area under the ROC')\n",
    "plt.plot(indice,result_metric['AUC'][2:18:1],':',label='AUC')\n",
    "plt.plot(indice,result_metric['Sensitivity'][2:18:1],'--',label='Sensitivity')\n",
    "plt.plot(indice,result_metric['Specificity'][2:18:1],'-.',label='Specificity')\n",
    "plt.plot(indice,result_metric['F1'][2:18:1],'-',label='F1')\n",
    "plt.scatter(indice,result_metric['AUC'][2:18:1],s=20)\n",
    "plt.scatter(indice,result_metric['Sensitivity'][2:18:1],s=20)\n",
    "plt.scatter(indice,result_metric['Specificity'][2:18:1],s=20)\n",
    "plt.scatter(indice,result_metric['F1'][2:18:1],s=20)\n",
    "plt.axvline(11,c='black',ls='-.')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(result_metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
